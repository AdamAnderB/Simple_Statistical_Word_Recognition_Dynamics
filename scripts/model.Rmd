`---
title: "word_rec"
author: "Adam A. Bramlett"
date: "2025-12-04"
output: html_document
---

```{r setup, include=FALSE}



```


```{r}
library(tibble)
library(purrr)
library(dplyr)
library(ggplot2)


# --- Block 1: Native-English Lexicon for beaker / speaker / beetle / carriage ---

# Words in the lexicon
lex_words <- c("beaker", "speaker", "beetle", "carriage")

# Cue means for the *native* environment
cue_means_native <- list(
  ONSET_FRIC = c(  # presence/strength of /s/-like frication at onset
    beaker   = 10,
    speaker  = 20,
    beetle   = 10,
    carriage = 30
  ),
  VOWEL_FRONT = c( # vowel frontness/height (e.g., F2-ish)
    beaker   = 80,  # /i/
    speaker  = 80,  # /i/
    beetle   = 80,  # /i/
    carriage = 50   # /æ/ish
  ),
  CODA_TYPE = c(   # abstract scalar for coda identity
    beaker   = 40,  # /kər/
    speaker  = 40,  # /kər/
    beetle   = 20,  # /təl/
    carriage = 60   # /dʒ/
  )
)

# Cue standard deviations (how variable tokens are around their means)
cue_sds_native <- list(
  ONSET_FRIC = c(
    beaker   = 5,
    speaker  = 5,
    beetle   = 5,
    carriage = 5
  ),
  VOWEL_FRONT = c(
    beaker   = 5,
    speaker  = 5,
    beetle   = 5,
    carriage = 5
  ),
  CODA_TYPE = c(
    beaker   = 5,
    speaker  = 5,
    beetle   = 5,
    carriage = 5
  )
)

# Helper to sample tokens for one word across all cues
sample_word_tokens <- function(word, n_tokens, cue_means, cue_sds) {
  w <- as.character(word)  # make sure it's a plain string
  
  tibble(
    word = w,
    cue_ONSET_FRIC = rnorm(
      n_tokens,
      mean = cue_means$ONSET_FRIC[w],
      sd   = cue_sds$ONSET_FRIC[w]
    ),
    cue_VOWEL_FRONT = rnorm(
      n_tokens,
      mean = cue_means$VOWEL_FRONT[w],
      sd   = cue_sds$VOWEL_FRONT[w]
    ),
    cue_CODA_TYPE = rnorm(
      n_tokens,
      mean = cue_means$CODA_TYPE[w],
      sd   = cue_sds$CODA_TYPE[w]
    )
  )
}

# Main function: generate native lexicon
make_beaker_lexicon_native <- function(n_tokens_per_word = 100, seed = NULL) {
  if (!is.null(seed)) set.seed(seed)
  
  lex <- map_dfr(
    lex_words,
    ~sample_word_tokens(.x, n_tokens_per_word, cue_means_native, cue_sds_native)
  )
  
  lex$id <- seq_len(nrow(lex))  # optional unique ID per token
  
  lex
}

# Example: build a native lexicon
lex_native <- make_beaker_lexicon_native(n_tokens_per_word = 100, seed = 123)

head(lex_native)
View(lex_native)
```

```{r}


ggplot(lex_native, aes(cue_ONSET_FRIC, cue_VOWEL_FRONT, color = word)) +
  geom_point(alpha = 0.5) +
  theme_minimal() +
  labs(title = "Native lexicon: ONSET_FRIC vs VOWEL_FRONT")

ggplot(lex_native, aes(cue_VOWEL_FRONT, cue_CODA_TYPE, color = word)) +
  geom_point(alpha = 0.5) +
  theme_minimal() +
  labs(title = "Native lexicon: VOWEL_FRONT vs CODA_TYPE")

```

```{r}

library(dplyr)
library(purrr)

# --- Block 2: Define the time schedule over cues ---

# Each time_step maps to the cue_* columns that are available at that time.
# You can add more cues later (e.g., "cue_SOMETHING_ELSE") and include them in the vectors.
time_schedule <- list(
  T1_ONSET = c("cue_ONSET_FRIC"),
  T2_VOWEL = c("cue_ONSET_FRIC", "cue_VOWEL_FRONT"),
  T3_CODA  = c("cue_ONSET_FRIC", "cue_VOWEL_FRONT", "cue_CODA_TYPE")
)

# --- Helper: expand a lexicon into time-stamped snapshots with masked cues ---

expand_lexicon_over_time <- function(lex_df, time_schedule) {
  # detect all cue columns generically
  cue_cols <- grep("^cue_", names(lex_df), value = TRUE)
  
  # for each time step, create a version of lex_df with only some cues visible
  imap_dfr(time_schedule, ~{
    step_name <- .y        # e.g. "T1_ONSET"
    visible_cues <- .x     # e.g. c("cue_ONSET_FRIC", "cue_VOWEL_FRONT")
    
    lex_step <- lex_df
    lex_step$time_step <- step_name
    
    # any cue not in visible_cues is hidden (set to NA)
    mask_cols <- setdiff(cue_cols, visible_cues)
    lex_step[mask_cols] <- lapply(lex_step[mask_cols], function(x) NA_real_)
    
    lex_step
  })
}

# --- Apply to your native lexicon from Block 1 ---

# assumes you already have lex_native from Block 1
# lex_native <- make_beaker_lexicon_native(n_tokens_per_word = 100, seed = 123)

lex_native_time <- expand_lexicon_over_time(lex_native, time_schedule)

head(lex_native_time)

View(lex_native_time)
```

```{r}
define_learner_priors_beaker <- function(
  words = lex_words,
  cues  = c("ONSET_FRIC", "VOWEL_FRONT", "CODA_TYPE"),
  cue_means = cue_means_native,
  cue_sds   = cue_sds_native
) {
  prior_list <- list()
  
  for (cue in cues) {
    # for this cue, create a named list of (mean, sd) per word
    cue_priors <- setNames(
      lapply(words, function(w) {
        list(
          mean = cue_means[[cue]][[w]],
          sd   = cue_sds[[cue]][[w]]
        )
      }),
      words
    )
    prior_list[[cue]] <- cue_priors
  }
  
  prior_list
}

# Label map: each word maps 1:1 to its own internal category
make_identity_label_map <- function(words) {
  setNames(
    lapply(words, function(w) {
      # internal category name same as word, weight 1
      setNames(1, w)
    }),
    words
  )
}


init_learner_beaker_native <- function(
  priors,
  attention = NULL,
  learning_rate = 0,   # 0 = static, no learning
  beta = 0
) {
  # infer cues & words from priors
  cue_names <- names(priors)
  words <- names(priors[[1]])
  
  # default: equal attention over cues if not provided
  if (is.null(attention)) {
    attention <- setNames(rep(1 / length(cue_names), length(cue_names)), cue_names)
  }
  
  # empty history structure (optional but useful)
  empty_history <- data.frame(
    trial        = integer(),
    pred         = character(),
    true         = character(),
    correct      = logical(),
    accuracy_num = numeric(),
    env          = character(),
    stringsAsFactors = FALSE
  )
  
  # add cue_ and attention_ columns to history
  for (cue in cue_names) {
    empty_history[[paste0("cue_", cue)]]       <- numeric()
    empty_history[[paste0("attention_", cue)]] <- numeric()
  }
  
  learner <- list(
    attention       = attention,
    learning_rate   = learning_rate,
    beta            = beta,
    categories      = priors,
    label_map       = make_identity_label_map(words),
    history         = empty_history,
    recent_accuracy = numeric(),
    # stub params, in case you ever reuse update_learner_general()
    explore_rate    = 0,
    update_rigidity = 1,
    adapt_threshold = 0
  )
  
  learner
}


priors_native <- define_learner_priors_beaker()
str(priors_native, max.level = 2)
```

```{r}
# Define native priors from Block 1 cue means
priors_native <- define_learner_priors_beaker()

# Example attention: equal over cues for now
attention_native <- c(
  ONSET_FRIC  = 1/3,
  VOWEL_FRONT = 1/3,
  CODA_TYPE   = 1/3
)

learner_native <- init_learner_beaker_native(
  priors    = priors_native,
  attention = attention_native,
  learning_rate = 0,  # static listener (no adaptation)
  beta = 0
)

str(learner_native, max.level = 2)
```

```{r}
# --- Simple static recognizer: likelihood + prediction ---

gauss_likelihood <- function(x, mean, sd) {
  dnorm(x, mean = mean, sd = sd)
}

`%||%` <- function(a, b) if (!is.null(a)) a else b

predict_label_general <- function(learner, cue_values) {
  cue_names <- names(cue_values)
  scores <- list()  # category-level scores
  
  # 1. Accumulate evidence for each internal category
  for (cue in cue_names) {
    if (!is.na(cue_values[[cue]]) && cue %in% names(learner$categories)) {
      for (cat in names(learner$categories[[cue]])) {
        cat_info <- learner$categories[[cue]][[cat]]
        lik <- gauss_likelihood(cue_values[[cue]], cat_info$mean, cat_info$sd)
        scores[[cat]] <- (scores[[cat]] %||% 0) +
          learner$attention[[cue]] * log(lik + 1e-10)
      }
    }
  }
  
  # 2. Map category scores to word labels using label_map
  label_scores <- setNames(
    numeric(length(learner$label_map)),
    names(learner$label_map)
  )
  
  for (label in names(label_scores)) {
    for (cat in names(learner$label_map[[label]])) {
      if (!is.null(scores[[cat]])) {
        label_scores[label] <- label_scores[label] +
          learner$label_map[[label]][[cat]] * scores[[cat]]
      }
    }
  }
  
  # 3. Return the best label
  names(which.max(label_scores))
}
```



```{r}
# --- Quick test: predict for one token at T1 and T3 ---

# Take one example token at each time step
example_T1 <- lex_native_time %>%
  dplyr::filter(time_step == "T1_ONSET") %>%
  dplyr::slice(1)

example_T3 <- lex_native_time %>%
  dplyr::filter(time_step == "T3_CODA") %>%
  dplyr::slice(1)

# Build cue_values lists with names matching learner$categories
cue_values_T1 <- list(
  ONSET_FRIC  = example_T1$cue_ONSET_FRIC,
  VOWEL_FRONT = example_T1$cue_VOWEL_FRONT,  # will be NA at T1
  CODA_TYPE   = example_T1$cue_CODA_TYPE     # NA at T1
)

cue_values_T3 <- list(
  ONSET_FRIC  = example_T3$cue_ONSET_FRIC,
  VOWEL_FRONT = example_T3$cue_VOWEL_FRONT,
  CODA_TYPE   = example_T3$cue_CODA_TYPE
)

# Model predictions
predict_label_general(learner_native, cue_values_T1)
predict_label_general(learner_native, cue_values_T3)
```

```{r}

# --- Block 4: Evaluate native listener over unfolding cues ---

# Helper: convert tibble row to a cue-value list
extract_cue_values <- function(row) {
  cue_cols <- grep("^cue_", names(row), value = TRUE)
  x <- as.list(row[cue_cols])
  
  # strip "cue_" prefix → learner expects names like "ONSET_FRIC"
  names(x) <- gsub("^cue_", "", names(x))
  
  x
}

# Apply predict_label_general to every token
evaluate_lexicon <- function(learner, lex_df) {
  lex_df %>%
    rowwise() %>%
    mutate(
      pred = predict_label_general(
        learner,
        extract_cue_values(cur_data())
      ),
      correct = pred == word,
      accuracy_num = as.numeric(correct)
    ) %>%
    ungroup()
}

# Run it
lex_eval <- evaluate_lexicon(learner_native, lex_native_time)

head(lex_eval)



```

```{r}

accuracy_by_time <- lex_eval %>%
  group_by(time_step) %>%
  summarize(accuracy = mean(accuracy_num), .groups = "drop")

accuracy_by_time

```



```{r}
ggplot(accuracy_by_time, aes(x = time_step, y = accuracy, group = 1)) +
  geom_line(size = 1.2) +
  geom_point(size = 3) +
  ylim(0, 1) +
  theme_minimal(base_size = 14) +
  labs(
    title = "Native Listener Recognition Accuracy Across the Unfolding Signal",
    x = "Time Step",
    y = "Accuracy"
  )



```

```{r}
library(tidyr)

# ============================================================
# Block 5 — Incremental Activation (TRACE-lite model)
# ============================================================

library(dplyr)
library(tidyr)
library(purrr)

# ---- 5A. Identify which cue is added at each time step ----

new_cue_for_step <- function(time_step, time_schedule) {
  this <- time_schedule[[time_step]]
  
  # find previous step's visible cues
  steps <- names(time_schedule)
  idx <- match(time_step, steps)
  
  if (idx == 1) {
    previous <- character(0)
  } else {
    previous <- time_schedule[[steps[idx - 1]]]
  }
  
  setdiff(this, previous)
}

cue_unveil <- map_chr(names(time_schedule), ~ new_cue_for_step(.x, time_schedule))
cue_unveil

compute_newcue_evidence <- function(learner, token_row, new_cue) {
  
  cue_value <- token_row[[new_cue]]
  
  # If masked → uniform evidence
  if (is.na(cue_value)) {
    words <- names(learner$label_map)
    return(setNames(rep(1 / length(words), length(words)), words))
  }
  
  cue_clean <- sub("^cue_", "", new_cue)
  
  liks <- map_dbl(learner$categories[[cue_clean]], function(cat_info) {
    dnorm(cue_value, mean = cat_info$mean, sd = cat_info$sd)
  })
  
  softmax <- function(x) exp(x) / sum(exp(x))
  softmax(liks)
}

update_activation <- function(prev, new, alpha = 0.3) {
  (1 - alpha) * prev + alpha * new
}

compute_incremental_activations <- function(learner, lex_df, alpha = 0.3) {
  
  words <- names(learner$label_map)
  steps <- names(time_schedule)
  
  out <- list()
  
  for (i in seq_len(nrow(lex_df))) {
    token <- lex_df[i, ]
    true_word <- token$word
    tid <- token$id
    
    # start uniform (nothing heard yet)
    prev_act <- setNames(rep(1 / length(words), length(words)), words)
    
    # ---------- NEW: T0 baseline row ----------
    out[[length(out) + 1]] <- tibble(
      word       = true_word,
      token_id   = tid,
      time_step  = "T0_BASE",
      competitor = names(prev_act),
      activation = as.numeric(prev_act)
    )
    # ------------------------------------------
    
    for (s in steps) {
      # find the cue that "unlocks" at this time step
      newcue_col <- new_cue_for_step(s, time_schedule)
      
      # compute new evidence
      ev <- compute_newcue_evidence(learner, token, newcue_col)
      
      # blend incremental activation
      updated <- update_activation(prev_act, ev, alpha = alpha)
      
      # store row
      out[[length(out) + 1]] <- tibble(
        word       = true_word,
        token_id   = tid,
        time_step  = s,
        competitor = names(updated),
        activation = as.numeric(updated)
      )
      
      prev_act <- updated
    }
  }
  
  bind_rows(out)
}

# Run it
activations_native <- compute_incremental_activations(
  learner = learner_native,
  lex_df = lex_native_time,
  alpha = 0.3
)

head(activations_native)
```


```{r}

activ_summary <- activations_native %>%
  group_by(word, time_step, competitor) %>%
  summarize(mean_act = mean(activation), .groups = "drop")

ggplot(
  activ_summary,
  aes(x = time_step, y = mean_act, color = competitor, group = competitor)
) +
  geom_line(size = 1.3) +
  geom_point(size = 3) +
  theme_minimal(base_size = 14) +
  labs(
    title = "Incremental Competitor Activation (New Cue Only)",
    x = "Time Step",
    y = "Activation"
  )+facet_wrap(word~.)


```



```{r}
# ============================================================
# Block 6 — Non-native learner & comparison
# ============================================================

# ---- 6A. Define L2 priors (noisier / less informative) ----

# Start from native means and tweak
cue_means_L2 <- cue_means_native

# Make onset frication less diagnostic for /s/
# (beaker & speaker closer; carriage not as extreme)
cue_means_L2$ONSET_FRIC["beaker"]   <- 15
cue_means_L2$ONSET_FRIC["speaker"]  <- 18
cue_means_L2$ONSET_FRIC["beetle"]   <- 15
cue_means_L2$ONSET_FRIC["carriage"] <- 18

# Make coda cues noisier (L2 listener struggles with final consonant)
cue_sds_L2 <- cue_sds_native
cue_sds_L2$CODA_TYPE[] <- 15  # big variance for all words

# Build L2 priors with these means/SDs
priors_L2 <- define_learner_priors_beaker(
  words    = lex_words,
  cues     = c("ONSET_FRIC", "VOWEL_FRONT", "CODA_TYPE"),
  cue_means = cue_means_L2,
  cue_sds   = cue_sds_L2
)

# ---- 6B. L2 learner: attention profile different from native ----

attention_L2 <- c(
  ONSET_FRIC  = 0.2,  # pays *less* attention to onset
  VOWEL_FRONT = 0.6,  # over-relies on vowel
  CODA_TYPE   = 0.2   # under-uses coda
)

learner_L2 <- init_learner_beaker_native(
  priors    = priors_L2,
  attention = attention_L2,
  learning_rate = 0,  # still static
  beta = 0
)

# ---- 6C. Compute incremental activations for L2 learner ----

activations_L2 <- compute_incremental_activations(
  learner = learner_L2,
  lex_df  = lex_native_time,
  alpha   = 0.3
)

# Tag each set with learner type
activations_native <- activations_native %>%
  mutate(learner = "Native")

activations_L2 <- activations_L2 %>%
  mutate(learner = "L2")

activ_all <- bind_rows(activations_native, activations_L2)

# ---- 6D. Summarize and plot comparison ----

activ_summary_all <- activ_all %>%
  group_by(learner, word, time_step, competitor) %>%
  summarize(mean_act = mean(activation), .groups = "drop")

ggplot(
  activ_summary_all,
  aes(x = time_step, y = mean_act, color = competitor, group = competitor)
) +
  geom_line(size = 1.1) +
  geom_point(size = 2.5) +
  theme_minimal(base_size = 14) +
  labs(
    title = "Incremental Competitor Activation: Native vs L2 Learner",
    x = "Time Step",
    y = "Activation"
  ) +
  facet_grid(learner ~ word)
```
```{r}
# ============================================================
# Block 6 — Two L2 learner types and comparison
# ============================================================

# ---- 6A. L2-English: perfect categories, bad vowel attention ----

# Same priors as native (perfect categories)
# -> we reuse `priors_native`

attention_L2_Eng <- c(
  ONSET_FRIC  = 0.45,  # over-weights onset
  VOWEL_FRONT = 0.10,  # under-uses vowel
  CODA_TYPE   = 0.45   # over-weights coda
)

learner_L2_Eng <- init_learner_beaker_native(
  priors        = priors_native,
  attention     = attention_L2_Eng,
  learning_rate = 0,
  beta          = 0
)

activations_L2_Eng <- compute_incremental_activations(
  learner = learner_L2_Eng,
  lex_df  = lex_native_time,
  alpha   = 0.3
)


# ---- 6B. Mandarin-lexicon listener (Mandarin-ish forms) ----

# Internal lexicon: plausible Mandarin-style forms
mandarin_words <- c("bi3ke4", "sipi1ke4", "bi3te4", "kai3li3")

# Mandarin-shaped cue means (still in your abstract cue space)
cue_means_mandarin <- list(
  ONSET_FRIC = c(
    bi3ke4   = 12,  # ~b-
    sipi1ke4 = 25,  # s+p cluster-ish
    bi3te4   = 12,
    kai3li3  = 18
  ),
  VOWEL_FRONT = c(
    bi3ke4   = 78,  # high/front-ish
    sipi1ke4 = 78,
    bi3te4   = 78,
    kai3li3  = 60   # lower/more central
  ),
  CODA_TYPE = c(
    bi3ke4   = 35,
    sipi1ke4 = 35,
    bi3te4   = 35,
    kai3li3  = 35   # collapsed: no strong coda contrast
  )
)

cue_sds_mandarin <- list(
  ONSET_FRIC = c(
    bi3ke4   = 7,
    sipi1ke4 = 7,
    bi3te4   = 7,
    kai3li3  = 7
  ),
  VOWEL_FRONT = c(
    bi3ke4   = 6,
    sipi1ke4 = 6,
    bi3te4   = 6,
    kai3li3  = 8
  ),
  CODA_TYPE = c(
    bi3ke4   = 20,
    sipi1ke4 = 20,
    bi3te4   = 20,
    kai3li3  = 20    # very noisy codas
  )
)

priors_mandarin <- define_learner_priors_beaker(
  words     = mandarin_words,
  cues      = c("ONSET_FRIC", "VOWEL_FRONT", "CODA_TYPE"),
  cue_means = cue_means_mandarin,
  cue_sds   = cue_sds_mandarin
)

attention_mandarin <- c(
  ONSET_FRIC  = 0.4,
  VOWEL_FRONT = 0.4,
  CODA_TYPE   = 0.2
)

learner_mandarin <- init_learner_beaker_native(
  priors        = priors_mandarin,
  attention     = attention_mandarin,
  learning_rate = 0,
  beta          = 0
)

activations_mandarin <- compute_incremental_activations(
  learner = learner_mandarin,
  lex_df  = lex_native_time,  # English tokens as input
  alpha   = 0.3
)


# ---- 6C. Combine all learners and plot ----

activations_native_labeled <- activations_native %>%
  mutate(learner = "Native_English")

activations_L2_Eng_labeled <- activations_L2_Eng %>%
  mutate(learner = "L2_Eng_perfect_cats")

activations_mandarin_labeled <- activations_mandarin %>%
  mutate(learner = "L1_Mandarin_lexicon")

activ_all <- bind_rows(
  activations_native_labeled,
  activations_L2_Eng_labeled,
  activations_mandarin_labeled
)

activ_summary_all <- activ_all %>%
  mutate(
    time_step = factor(
      time_step,
      levels = c("T0_BASE", names(time_schedule))
    )
  ) %>%
  group_by(learner, word, time_step, competitor) %>%
  summarize(mean_act = mean(activation), .groups = "drop")

ggplot(
  activ_summary_all,
  aes(x = time_step, y = mean_act, color = competitor, group = competitor)
) +
  geom_line(size = 1.1) +
  geom_point(size = 2.5) +
  theme_minimal(base_size = 13) +
  labs(
    title = "Incremental Competitor Activation: Native vs L2 variants",
    x = "Time Step",
    y = "Activation"
  ) +
  facet_grid(learner ~ word)

```

```{r}
# ------------------------------------------------------------
# 6B. L2 type 2: Mandarin lexical entries (no English words)
# ------------------------------------------------------------

# Internal lexicon: pretend the learner only has these Mandarin words
mandarin_words <- c("zhou1", "jiu1", "qiu1", "shou1")

# For now, reuse the *numeric* cue means/SDs, but assign them to Mandarin labels.
# You can later tweak these to be more Mandarin-like.
cue_means_Mandarin <- list(
  ONSET_FRIC = setNames(
    as.numeric(cue_means_native$ONSET_FRIC),
    mandarin_words
  ),
  VOWEL_FRONT = setNames(
    as.numeric(cue_means_native$VOWEL_FRONT),
    mandarin_words
  ),
  CODA_TYPE = setNames(
    as.numeric(cue_means_native$CODA_TYPE),
    mandarin_words
  )
)

cue_sds_Mandarin <- list(
  ONSET_FRIC = setNames(
    as.numeric(cue_sds_native$ONSET_FRIC),
    mandarin_words
  ),
  VOWEL_FRONT = setNames(
    as.numeric(cue_sds_native$VOWEL_FRONT),
    mandarin_words
  ),
  CODA_TYPE = setNames(
    as.numeric(cue_sds_native$CODA_TYPE),
    mandarin_words
  )
)

# Optionally: make these categories a bit "messed up"
# e.g., more overlap and noisier codas
cue_means_Mandarin$ONSET_FRIC[] <- mean(cue_means_Mandarin$ONSET_FRIC)  # collapse onset
cue_sds_Mandarin$CODA_TYPE[]    <- 15                                   # noisy codas

# Define priors for Mandarin lexicon
define_learner_priors_mandarin <- function(
  words = mandarin_words,
  cues  = c("ONSET_FRIC", "VOWEL_FRONT", "CODA_TYPE"),
  cue_means = cue_means_Mandarin,
  cue_sds   = cue_sds_Mandarin
) {
  prior_list <- list()
  
  for (cue in cues) {
    cue_priors <- setNames(
      lapply(words, function(w) {
        list(
          mean = cue_means[[cue]][[w]],
          sd   = cue_sds[[cue]][[w]]
        )
      }),
      words
    )
    prior_list[[cue]] <- cue_priors
  }
  
  prior_list
}

priors_Mandarin <- define_learner_priors_mandarin()

# Attention for Mandarin learner (you can tune this)
attention_Mandarin <- c(
  ONSET_FRIC  = 0.3,
  VOWEL_FRONT = 0.4,
  CODA_TYPE   = 0.3
)

learner_L2_Mandarin <- init_learner_beaker_native(
  priors        = priors_Mandarin,
  attention     = attention_Mandarin,
  learning_rate = 0,
  beta          = 0
)

# Incremental activations (note: competitor = Mandarin words)
activations_L2_Mandarin <- compute_incremental_activations(
  learner = learner_L2_Mandarin,
  lex_df  = lex_native_time,
  alpha   = 0.3
) %>%
  mutate(learner = "L2_Mandarin")

# Combine with native for comparison
activ_all_2 <- bind_rows(activations_native_tagged, activations_L2_Mandarin)

activ_summary_2 <- activ_all_2 %>%
  group_by(learner, word, time_step, competitor) %>%
  summarize(mean_act = mean(activation), .groups = "drop")

ggplot(
  activ_summary_2,
  aes(x = time_step, y = mean_act, color = competitor, group = competitor)
) +
  geom_line(size = 1.1) +
  geom_point(size = 2.5) +
  theme_minimal(base_size = 14) +
  labs(
    title = "Incremental Activation: Native English vs L2 with Mandarin Lexicon",
    x = "Time Step",
    y = "Activation"
  ) +
  facet_grid(learner ~ word)


```

```{r}
# ============================================================
# Block 7 — Mandarin tonal words: English vs Native Mandarin
# ============================================================

# Idea:
# - New lexicon: Mandarin-style minimal set differing mainly in "tone"
#   We reuse CODA_TYPE as a "TONE" dimension here.
# - Same 3 cues:
#   ONSET_FRIC  ~ onset-ish
#   VOWEL_FRONT ~ segmental vowel quality
#   CODA_TYPE   ~ TONE (late, most informative cue)
#
# - lex_mand_time: Mandarin tokens unfolding over T1 (onset), T2 (vowel),
#                  T3 (tone-as-coda).
# - Two listeners:
#   (1) English listener on Mandarin words: under-uses tone.
#   (2) Native Mandarin listener: strongly uses tone.

# ---- 7A. Define Mandarin tonal lexicon in cue space ----

mand_words <- c("bi1", "bi2", "bi3", "bi4")

cue_means_mand_tone <- list(
  ONSET_FRIC = c(
    bi1 = 10,
    bi2 = 10,
    bi3 = 10,
    bi4 = 10    # same onset across tones
  ),
  VOWEL_FRONT = c(
    bi1 = 80,
    bi2 = 80,
    bi3 = 80,
    bi4 = 80    # same segmental vowel
  ),
  CODA_TYPE = c(
    bi1 = 20,   # use this as a "tone" cue
    bi2 = 40,
    bi3 = 60,
    bi4 = 80
  )
)

cue_sds_mand_tone <- list(
  ONSET_FRIC = c(
    bi1 = 5,
    bi2 = 5,
    bi3 = 5,
    bi4 = 5
  ),
  VOWEL_FRONT = c(
    bi1 = 5,
    bi2 = 5,
    bi3 = 5,
    bi4 = 5
  ),
  CODA_TYPE = c(
    bi1 = 5,
    bi2 = 5,
    bi3 = 5,
    bi4 = 5
  )
)

# Build Mandarin tonal lexicon using the same sampler
make_mandarin_tone_lexicon <- function(n_tokens_per_word = 100, seed = NULL) {
  if (!is.null(seed)) set.seed(seed)
  
  lex <- map_dfr(
    mand_words,
    ~sample_word_tokens(.x, n_tokens_per_word,
                        cue_means = cue_means_mand_tone,
                        cue_sds   = cue_sds_mand_tone)
  )
  lex$id <- seq_len(nrow(lex))
  lex
}

lex_mand <- make_mandarin_tone_lexicon(n_tokens_per_word = 100, seed = 456)

lex_mand_time <- expand_lexicon_over_time(lex_mand, time_schedule)

# Optional quick sanity check:
# head(lex_mand_time)


# ---- 7B. Native Mandarin listener: strong tone use ----

priors_mand_native <- define_learner_priors_beaker(
  words     = mand_words,
  cues      = c("ONSET_FRIC", "VOWEL_FRONT", "CODA_TYPE"),
  cue_means = cue_means_mand_tone,
  cue_sds   = cue_sds_mand_tone
)

attention_mand_native <- c(
  ONSET_FRIC  = 0.2,
  VOWEL_FRONT = 0.2,
  CODA_TYPE   = 0.6   # tone-weighted
)

learner_mand_native <- init_learner_beaker_native(
  priors        = priors_mand_native,
  attention     = attention_mand_native,
  learning_rate = 0,
  beta          = 0
)

activ_mand_native <- compute_incremental_activations(
  learner = learner_mand_native,
  lex_df  = lex_mand_time,
  alpha   = 0.3
) %>%
  mutate(learner = "Mandarin_native")


# ---- 7C. English listener on Mandarin words: weak tone use ----

# Here: same *means* (they hear acoustic differences),
# but they don't treat "tone" as a stable linguistic cue:
#   - Tone dimension very noisy
#   - Very low attention to CODA_TYPE

cue_means_Eng_on_Mand <- cue_means_mand_tone

cue_sds_Eng_on_Mand <- cue_sds_mand_tone
cue_sds_Eng_on_Mand$CODA_TYPE[] <- 25  # very noisy tone estimates

priors_Eng_on_Mand <- define_learner_priors_beaker(
  words     = mand_words,
  cues      = c("ONSET_FRIC", "VOWEL_FRONT", "CODA_TYPE"),
  cue_means = cue_means_Eng_on_Mand,
  cue_sds   = cue_sds_Eng_on_Mand
)

attention_Eng_on_Mand <- c(
  ONSET_FRIC  = 0.45,
  VOWEL_FRONT = 0.45,
  CODA_TYPE   = 0.10  # heavily under-weights tone
)

learner_Eng_on_Mand <- init_learner_beaker_native(
  priors        = priors_Eng_on_Mand,
  attention     = attention_Eng_on_Mand,
  learning_rate = 0,
  beta          = 0
)

activ_Eng_on_Mand <- compute_incremental_activations(
  learner = learner_Eng_on_Mand,
  lex_df  = lex_mand_time,
  alpha   = 0.3
) %>%
  mutate(learner = "English_listener_on_Mandarin")


# ---- 7D. Summarize & plot Mandarin tonal competition ----

activ_mand_all <- bind_rows(
  activ_mand_native,
  activ_Eng_on_Mand
)

activ_mand_summary <- activ_mand_all %>%
  mutate(
    time_step = factor(
      time_step,
      levels = c("T0_BASE", names(time_schedule))
    )
  ) %>%
  group_by(learner, word, time_step, competitor) %>%
  summarize(mean_act = mean(activation), .groups = "drop")

ggplot(
  activ_mand_summary,
  aes(x = time_step, y = mean_act, color = competitor, group = competitor)
) +
  geom_line(size = 1.1) +
  geom_point(size = 2.5) +
  theme_minimal(base_size = 13) +
  labs(
    title = "Mandarin Tonal Words: English vs Native Mandarin Listener",
    x = "Time Step",
    y = "Activation"
  ) +
  facet_grid(learner ~ word)





```
```{r}
# ============================================================
# Block 7 — Mandarin-like tone lexicon & multiple learners
# ============================================================

library(dplyr)
library(tidyr)
library(purrr)
library(ggplot2)

# ------------------------------------------------------------
# 7A. Mandarin-like lexicon (tone as "vowel" / F0 dimension)
# ------------------------------------------------------------

mand_words <- c("bi1ke4", "bi2ke4", "bi3ke4", "bi4ke4")

# Only VOWEL_FRONT (F0-ish) is truly diagnostic.
# ONSET_FRIC and CODA_TYPE are basically constant placeholders.
cue_means_mand <- list(
  ONSET_FRIC = c(
    bi1ke4 = 10,
    bi2ke4 = 10,
    bi3ke4 = 10,
    bi4ke4 = 10
  ),
  VOWEL_FRONT = c(   # this is doing the tone work
    bi1ke4 = 80,
    bi2ke4 = 60,
    bi3ke4 = 40,
    bi4ke4 = 20
  ),
  CODA_TYPE = c(
    bi1ke4 = 40,
    bi2ke4 = 40,
    bi3ke4 = 40,
    bi4ke4 = 40
  )
)

cue_sds_mand <- list(
  ONSET_FRIC = c(
    bi1ke4 = 5,
    bi2ke4 = 5,
    bi3ke4 = 5,
    bi4ke4 = 5
  ),
  VOWEL_FRONT = c(
    bi1ke4 = 5,
    bi2ke4 = 5,
    bi3ke4 = 5,
    bi4ke4 = 5
  ),
  CODA_TYPE = c(
    bi1ke4 = 5,
    bi2ke4 = 5,
    bi3ke4 = 5,
    bi4ke4 = 5
  )
)

# Use your existing sampling helper
make_mand_lexicon <- function(n_tokens_per_word = 100, seed = NULL) {
  if (!is.null(seed)) set.seed(seed)
  lex <- map_dfr(
    mand_words,
    ~sample_word_tokens(.x, n_tokens_per_word, cue_means_mand, cue_sds_mand)
  )
  lex$id <- seq_len(nrow(lex))
  lex
}

lex_mand <- make_mand_lexicon(n_tokens_per_word = 100, seed = 2025)

# Re-use your time_schedule + masking logic
lex_mand_time <- expand_lexicon_over_time(lex_mand, time_schedule)

# Small sanity plots
ggplot(lex_mand, aes(cue_VOWEL_FRONT, fill = word)) +
  geom_density(alpha = 0.4) +
  theme_minimal() +
  labs(
    title = "Mandarin-like lexicon: tone-ish VOWEL_FRONT distributions",
    x = "VOWEL_FRONT (F0-ish)",
    y = "Density"
  )

# ------------------------------------------------------------
# 7B. Priors helper for Mandarin lexicon
# (re-using beaker-style prior builder)
# ------------------------------------------------------------

define_learner_priors_mand <- function(
  words    = mand_words,
  cues     = c("ONSET_FRIC", "VOWEL_FRONT", "CODA_TYPE"),
  cue_means = cue_means_mand,
  cue_sds   = cue_sds_mand
) {
  define_learner_priors_beaker(
    words    = words,
    cues     = cues,
    cue_means = cue_means,
    cue_sds   = cue_sds
  )
}

cues_mand <- c("ONSET_FRIC", "VOWEL_FRONT", "CODA_TYPE")

# ------------------------------------------------------------
# 7C. Native Mandarin listener (baseline)
# ------------------------------------------------------------

priors_native_mand <- define_learner_priors_mand(
  words     = mand_words,
  cues      = cues_mand,
  cue_means = cue_means_mand,
  cue_sds   = cue_sds_mand
)

attention_native_mand <- c(
  ONSET_FRIC  = 0.1,
  VOWEL_FRONT = 0.8,  # heavily tone/F0-driven
  CODA_TYPE   = 0.1
)

learner_native_mand <- init_learner_beaker_native(
  priors    = priors_native_mand,
  attention = attention_native_mand,
  learning_rate = 0,
  beta = 0
)

activ_native_mand <- compute_incremental_activations(
  learner = learner_native_mand,
  lex_df  = lex_mand_time,
  alpha   = 0.3
) %>%
  mutate(learner = "Native_Mandarin")

# ------------------------------------------------------------
# 7D. L2 profile 1: knows categories, low F0 attention
# (good categories, but under-weights tone-ish cue)
# ------------------------------------------------------------

priors_L2_know_lowF0 <- define_learner_priors_mand(
  words     = mand_words,
  cues      = cues_mand,
  cue_means = cue_means_mand,  # same category means as native
  cue_sds   = cue_sds_mand
)

attention_L2_know_lowF0 <- c(
  ONSET_FRIC  = 0.45,
  VOWEL_FRONT = 0.10,  # low attention to tone/F0
  CODA_TYPE   = 0.45
)

learner_L2_know_lowF0 <- init_learner_beaker_native(
  priors    = priors_L2_know_lowF0,
  attention = attention_L2_know_lowF0,
  learning_rate = 0,
  beta = 0
)

activ_L2_know_lowF0 <- compute_incremental_activations(
  learner = learner_L2_know_lowF0,
  lex_df  = lex_mand_time,
  alpha   = 0.3
) %>%
  mutate(learner = "L2_knowCats_lowF0")

# ------------------------------------------------------------
# 7E. L2 profile 2: does NOT know categories, high F0 attention
# (tone dimension is treated as noisy / non-lexical)
# ------------------------------------------------------------

# Collapse VOWEL_FRONT means (no lexical contrast in priors)
cue_means_noCats <- cue_means_mand
collapsed_val <- mean(cue_means_mand$VOWEL_FRONT)
cue_means_noCats$VOWEL_FRONT[] <- collapsed_val

priors_L2_noCats_highF0 <- define_learner_priors_mand(
  words     = mand_words,
  cues      = cues_mand,
  cue_means = cue_means_noCats,
  cue_sds   = cue_sds_mand
)

attention_L2_noCats_highF0 <- c(
  ONSET_FRIC  = 0.1,
  VOWEL_FRONT = 0.8,  # strongly attends to F0, but priors say "no contrast"
  CODA_TYPE   = 0.1
)

learner_L2_noCats_highF0 <- init_learner_beaker_native(
  priors    = priors_L2_noCats_highF0,
  attention = attention_L2_noCats_highF0,
  learning_rate = 0,
  beta = 0
)

activ_L2_noCats_highF0 <- compute_incremental_activations(
  learner = learner_L2_noCats_highF0,
  lex_df  = lex_mand_time,
  alpha   = 0.3
) %>%
  mutate(learner = "L2_noCats_highF0")

# ------------------------------------------------------------
# 7F. L2 profile 3: hybrid (partially compressed categories + mid F0)
# ------------------------------------------------------------

cue_means_hybrid <- cue_means_mand

# Compress category means toward the center (less distinct tones)
mid_val <- mean(cue_means_mand$VOWEL_FRONT)
cue_means_hybrid$VOWEL_FRONT <- mid_val + 0.5 * (cue_means_mand$VOWEL_FRONT - mid_val)

priors_L2_hybrid <- define_learner_priors_mand(
  words     = mand_words,
  cues      = cues_mand,
  cue_means = cue_means_hybrid,
  cue_sds   = cue_sds_mand
)

attention_L2_hybrid <- c(
  ONSET_FRIC  = 0.25,
  VOWEL_FRONT = 0.50,  # uses tone, but categories are squished
  CODA_TYPE   = 0.25
)

learner_L2_hybrid <- init_learner_beaker_native(
  priors    = priors_L2_hybrid,
  attention = attention_L2_hybrid,
  learning_rate = 0,
  beta = 0
)

activ_L2_hybrid <- compute_incremental_activations(
  learner = learner_L2_hybrid,
  lex_df  = lex_mand_time,
  alpha   = 0.3
) %>%
  mutate(learner = "L2_hybrid")

# ------------------------------------------------------------
# 7G. L2 profile 4: knows categories, F0 is blurry, high F0 attention
# ------------------------------------------------------------

cue_sds_blurry <- cue_sds_mand
cue_sds_blurry$VOWEL_FRONT[] <- 15  # noisy tone perception

priors_blurryCats_highF0 <- define_learner_priors_mand(
  words     = mand_words,
  cues      = cues_mand,
  cue_means = cue_means_mand,   # correct category means
  cue_sds   = cue_sds_blurry    # but blurred F0 distributions
)

attention_blurryCats_highF0 <- c(
  ONSET_FRIC  = 0.1,
  VOWEL_FRONT = 0.8,   # leans on a noisy F0 channel
  CODA_TYPE   = 0.1
)

learner_L2_blurryCats_highF0 <- init_learner_beaker_native(
  priors    = priors_blurryCats_highF0,
  attention = attention_blurryCats_highF0,
  learning_rate = 0,
  beta = 0
)

activ_L2_blurryCats_highF0 <- compute_incremental_activations(
  learner = learner_L2_blurryCats_highF0,
  lex_df  = lex_mand_time,
  alpha   = 0.3
) %>%
  mutate(learner = "L2_blurryCats_highF0")

# ------------------------------------------------------------
# 7H. Combine & plot
# ------------------------------------------------------------

activ_all <- bind_rows(
  activ_native_mand,
  activ_L2_know_lowF0,
  activ_L2_noCats_highF0,
  activ_L2_hybrid,
  activ_L2_blurryCats_highF0
)

# Order time steps nicely, including T0_BASE
activ_all$time_step <- factor(
  activ_all$time_step,
  levels = c("T0_BASE", "T1_ONSET", "T2_VOWEL", "T3_CODA")
)

activ_summary_all <- activ_all %>%
  group_by(learner, word, time_step, competitor) %>%
  summarize(mean_act = mean(activation), .groups = "drop")

ggplot(
  activ_summary_all,
  aes(x = time_step, y = mean_act, color = competitor, group = competitor)
) +
  geom_line(size = 1.1) +
  geom_point(size = 2.5) +
  theme_minimal(base_size = 14) +
  labs(
    title = "Incremental Competitor Activation: Mandarin native vs L2 profiles",
    x = "Time Step",
    y = "Activation"
  ) +
  facet_grid(learner ~ word)

```

