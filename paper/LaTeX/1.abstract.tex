\begin{abstract}
Spoken-word recognition unfolds incrementally: as acoustic cues arrive, listeners activate multiple lexical candidates and update these hypotheses over time (e.g., TRACE; \cite{McClellandElman1986,Allopenna1998,Tanenhaus1995}). While this process is universal, languages differ sharply in how much they rely on segmental versus prosodic information, and these differences shape the dynamics of lexical competition\cite{CutlerClifton1984}. This paper introduces a small, transparent statistical model that simulates incremental activation from continuous cues. Words are represented as trajectories over acoustic dimensions, and listeners differ only in their cue weights, representational precision, or both. Using simple lexicons in three typologically distinct systems—English, Mandarin, and Italian—I show how the model reproduces the characteristic competition patterns of each language: segment-driven cohort effects in English, prosodic divergence in Mandarin tone sets, and mixed segment–prosody interactions in Italian stress minimal pairs. The goal is modest, to demonstrate how far incremental activation can go with minimal machinery, and to provide a compact foundation for future work on prediction, adaptation, and L2 speech learning. The simulations recover the expected competition patterns in all three languages, showing that a single, continuous cue–integration system is sufficient to generate these cross-linguistic time-course signatures.

\end{abstract}

\noindent\textbf{Index Terms}: computational modeling, spoken word recognition, prosody, segmental cues, cue weighting, incremental activation
